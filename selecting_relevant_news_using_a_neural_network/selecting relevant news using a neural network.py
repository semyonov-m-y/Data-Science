'''
–ü–∏—à–µ–º —Å–∏—Å—Ç–µ–º—É –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ—Ö–æ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π.
________________________________________
–ù–∞—à –¥–∞—Ç–∞—Å–µ—Ç —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ –∏–º–µ–µ—Ç —Ç–µ–º—ã - topic ("–°–ø–æ—Ä—Ç", "–ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–∏–∫–∞", ...) –∏ —Ç—ç–≥–∏ tag ("–§—É—Ç–±–æ–ª", "–¢–µ—Ö–Ω–∏–∫–∞", "–ö–æ—Å–º–æ—Å", ...).
1.	–í–æ–∑—å–º–µ–º –Ω–æ–≤–æ—Å—Ç–∏, –ø–æ–º–µ—á–µ–Ω–Ω—ã–µ –æ–¥–Ω–∏–º —Ç—ç–≥–æ–º –∏ —Ä–∞–∑–æ–±—å–µ–º –Ω–∞ –µ—â–µ –±–æ–ª–µ–µ –º–∞–ª–µ–Ω—å–∫–∏–µ –≥—Ä—É–ø–ø—ã –ø–æ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤.
2.	–ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É, —Ä–µ–∞–ª–∏–∑—É—é—â—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Word2Vec –æ—Ç gensim –∏ –≥–æ—Ç–æ–≤—ã–µ –≤–µ—Å–∞ –¥–ª—è –Ω–µ–µ –æ—Ç RusVectores. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç—ã –≤ –Ω–∞–±–æ—Ä—ã —á–∏—Å–µ–ª.
3.	–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è üìù –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ - —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –≥—Ä—É–ø–ø—ã –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏–∑ sklearn.

'''
import nltk #–¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏
import numpy as np
import pandas as pd
from gensim.models import KeyedVectors #–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç word2vec
from nltk.tokenize import word_tokenize
from pymystem3 import Mystem #–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–ª–æ–≤ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ —Å–ª–æ–≤–∞
from tqdm.notebook import tqdm #—Ä–∏—Å—É–µ–º –ª–∏–Ω–∏–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞, —á—Ç–æ–±—ã –ø–æ–Ω–∏–º–∞—Ç—å –∫–∞–∫ –¥–æ–ª–≥–æ —á—Ç–æ-—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
from sklearn.cluster import KMeans
from wget import download

nltk.download('punkt') #–∑–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Å–ª–æ–≤–∞

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
from IPython.display import display
pd.set_option('display.max_colwidth', 200)

# –°–∫–∞—á–∏–≤–∞–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ pip install wget --quiet
download('https://rusvectores.org/static/models/rusvectores4/news/news_upos_cbow_600_2_2018.vec.gz','news_upos_cbow_600_2_2018.vec.gz')

#–ö–æ–º–∞–Ω–¥–∞ %% time –≤ –Ω–∞—á–∞–ª–µ —è—á–µ–π–∫–∏ –∑–∞–º–µ—Ä—è–µ—Ç –≤—Ä–µ–º—è –µ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
# –°–∫–∞—á–∏–≤–∞–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è ‚âà2-3 –º–∏–Ω—É—Ç—ã
word2vec = KeyedVectors.load_word2vec_format('news_upos_cbow_600_2_2018.vec.gz')

# –ê—Ç—Ä–∏–±—É—Ç index_to_key –æ–±—ä–µ–∫—Ç–∞ word2vec —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å
word2vec.index_to_key

# –£ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å: –¥–ª—è –µ–µ –æ–±—É—á–µ–Ω–∏—è –∫ —Å–ª–æ–≤–∞–º —Ü–µ–ø–ª—è–ª–∏ —Ç—ç–≥–∏ —Å —á–∞—Å—Ç—å—é —Ä–µ—á–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, '–≥–æ–¥_NOUN', '—Å–æ–æ–±—â–∞—Ç—å_VERB'.
# –ß—Ç–æ–±—ã —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –æ–±—ã—á–Ω–æ–µ —Å–ª–æ–≤–æ –∏ —Å–ª–æ–≤–æ —Å —Ç—ç–≥–æ–º –∏–∑ –º–æ–¥–µ–ª–∏, —Å–æ—Å—Ç–∞–≤–∏–º —Å–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è.
# –ú–µ—Ç–æ–¥ split —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Å–ª–æ–≤–æ –Ω–∞ —Å–ø–∏—Å–æ–∫ –ø–æ–¥—Å–ª–æ–≤ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É —Å–∏–º–≤–æ–ª—É
'–≥–æ–¥_NOUN'.split('_')

# –í –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö –∏–∑ —Å–ø–∏—Å–∫–∞ –ø–æ–ª—É—á–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç (–Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 0)
'–≥–æ–¥_NOUN'.split('_')[0]

# –°–æ–∑–¥–∞–¥–∏–º —Å–ª–æ–≤–∞—Ä—å –≤–∏–¥–∞ {—Å–ª–æ–≤–æ: —Å–ª–æ–≤–æ_–¢–≠–ì}. –í –∫–æ–Ω—Ü–µ —Å–ø–∏—Å–∫–∞ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Ç—ç–≥–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, '–≥–æ–¥_NOUN' '–≥–æ–¥_PROPN'
# –∏–ª–∏ ['–¥–∞–≤–∞—Ç—å_VERB', '–¥–∞–≤–∞—Ç—å_NOUN', '–¥–∞–≤–∞—Ç—å_ADJ', '–¥–∞–≤–∞—Ç—å_PROPN', '–¥–∞–≤–∞—Ç—å_NUM']
# –ü–æ—ç—Ç–æ–º—É –±—É–¥–µ–º –±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –≤–µ—Ä—Å–∏—é —Å–ª–æ–≤–∞, –∏ –µ—Å–ª–∏ –æ–Ω–æ —É–∂–µ –µ—Å—Ç—å –≤ —Å–ª–æ–≤–∞—Ä–µ, –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –µ–≥–æ –Ω–µ –±—É–¥–µ–º
lemma2word = {}

for tagged_word in word2vec.index_to_key:
    word = tagged_word.split('_')[0]
    if word not in lemma2word:
        lemma2word[word] = tagged_word

lemma2word['–¥–∞–≤–∞—Ç—å']
'''
–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
–î–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –∏–º–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ, –Ω—É–∂–Ω–æ –ø—Ä–∏–¥–∞—Ç—å —Ç–µ–∫—Å—Ç—É —á–∏—Å–ª–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É.–î–ª—è —ç—Ç–æ–≥–æ —Å–¥–µ–ª–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é.
–ù–∞–º –Ω—É–∂–Ω–æ –ø—Ä–æ–π—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞–¥–∏–π: —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è ‚Üí –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è ‚Üí –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è. üìù –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è - –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–ª–æ–≤–∞(—Ç–æ–∫–µ–Ω - 
–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞ —è–∑—á–∫–∞, –∏–º–µ—é—â–∞—è —Å–º—ã—Å–ª) üë®üèªüíª –í–æ–ø—Ä–æ—Å: –º–æ–∂–Ω–æ –ª–∏ –Ω–∞–∑–≤–∞—Ç—å –±—É–∫–≤—É —Ç–æ–∫–µ–Ω–æ–º? üìù 
–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è - –ø–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º—ã —Å–ª–æ–≤–∞: "–≥–æ–¥—ã", "–≥–æ–¥—É" ‚Üí "–≥–æ–¥" üìù –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è - –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ –Ω–∞–±–æ—Ä —á–∏—Å–µ–ª - 
–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ.–ù–∞–ø—Ä–∏–º–µ—Ä, "–≥–æ–¥" ‚Üí (0.1, 0, 1.2, 3) üìù –í–µ–∫—Ç–æ—Ä - –Ω–∞–±–æ—Ä —á–∏—Å–µ–ª, –Ω–∞–ø—Ä–∏–º–µ—Ä, (0.1, 0, 1.2, 3).–ù–∞–¥ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –º–æ–∂–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å 
–∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ —á–∏—Å–ª–∞–º - –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ø–∞—Ä–Ω–æ–µ —Å–ª–æ–∂–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: (1, 2, 5) + (3, 4, 0) = (4, 6, 5) –∏–ª–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –Ω–∏–º–∏. 
–ù–∞ –æ—Å–Ω–æ–≤–µ –±–ª–∏–∑–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ç–µ–∫—Å—Ç–æ–≤ –º—ã –∏ –±—É–¥–µ–º –∏—Å–∫–∞—Ç—å –ø–æ—Ö–æ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏.
'''
# –ü—Ä–∏–º–µ—Ä —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏
word_tokenize('–ú–æ—Ä–æ–∑ –∏ —Å–æ–ª–Ω—Ü–µ, –¥–µ–Ω—å —á—É–¥–µ—Å–Ω—ã–π', language='russian')

# mystem - –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏
mystem = Mystem()

# –§—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—ç–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ñ–æ—Ä–º—ã —Å–ª–æ–≤–∞ –∏–∑ –º–æ–¥–µ–ª–∏ Word2Vec
def get_w2v_word(word):
    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é —Ñ–æ—Ä–º—É —Å–ª–æ–≤–∞
    lemma = mystem.lemmatize(word)[0]
    # –ë–µ—Ä–µ–º —Ç—ç–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ–æ—Ä–º—É –∏–∑ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ä–∞–Ω–µ–µ —Å–ª–æ–≤–∞—Ä—è
    w2v_word = lemma2word.get(lemma)
    return w2v_word

get_w2v_word("–ú–æ—Ä–æ–∑")
get_w2v_word("–¥–∞—é")

# –§—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞ –∏–∑ –º–æ–¥–µ–ª–∏ Word2Vec
def vectorize_sentence(txt):
    words = word_tokenize(txt, language='russian')
    vectors = []
    for word in words:
        tagged_word = get_w2v_word(word)
        if tagged_word is not None:
            vector = word2vec[tagged_word] #–ø–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, —Ç–æ –µ—Å—Ç—å –≤–µ—Å–∞
            vectors.append(vector)
    return np.mean(vectors, axis=0) #–ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ —Å—á–∏—Ç–∞–µ–º –Ω–µ –æ–±—â–µ–µ –æ–¥–Ω–æ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –∞ –∫–∞–∂–¥–æ–µ, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å 1 –≤–µ–∫—Ç–æ—Ä, —Å—Ö–ª–æ–ø–Ω—É–≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ 1
#–ø–æ–ª—É—á–∏–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–æ–º –∏–∑ 600 —á–∏—Å–µ–ª, –º–∞–ª—ã–µ –ø–æ –º–æ–¥—É–ª—é –∏ –≤ -2/-3/-4 —Å—Ç–µ–ø–µ–Ω–∏
vectorize_sentence('–ú–æ—Ä–æ–∑ –∏ —Å–æ–ª–Ω—Ü–µ, –¥–µ–Ω—å —á—É–¥–µ—Å–Ω—ã–π')

#–í–æ–∑—å–º–µ–º –¥–∞–Ω–Ω—ã–µ –æ –Ω–æ–≤–æ—Å—Ç—è—Ö —Å Lenta.ru
data = pd.read_csv('https://raw.githubusercontent.com/anastasiarazb/skillbox_nlp_demo/master/lenta_example.csv',sep=',')

# –í—ã–≤–µ–¥–µ–º —Å–ø–∏—Å–∫–∏ —Ç–µ–º –∏ —Ç—ç–≥–æ–≤ —Å–æ —Å—á–µ—Ç—á–∏–∫–æ–º —á–∏—Å–ª–∞ —Å—Ç–∞—Ç–µ–π –≤ —ç—Ç–∏—Ö –≥—Ä—É–ø–ø–∞—Ö. –§—É–Ω–∫—Ü–∏—è groupby –ø–æ —Å–ø–∏—Å–∫—É –∫–æ–ª–æ–Ω–æ–∫ ['topic', 'tags'] –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ,
# –∞ count() - –¥–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ
data.groupby(['topic', 'tags']).count()

# –í —Ç–µ–º–µ '–≠–∫–æ–Ω–æ–º–∏–∫–∞' –≤–æ–∑—å–º–µ–º —Ç—ç–≥ 'undefined' –∏ –∏—Å—Å–ª–µ–¥—É–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –≤ –Ω–µ–º
data_tag = data[
    (data['topic'] == '–≠–∫–æ–Ω–æ–º–∏–∫–∞')
    & (data['tags'] == 'undefined')
    ].copy()

# üë®üèªüíª –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é —Ç–µ–º—ã –∏ —Ç—ç–≥–∞, –Ω–∞–ø—Ä. "–ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–∏–∫–∞"+"–¢–µ—Ö–Ω–∏–∫–∞"
data_tag.shape

# –ü—Ä–µ–¥—Å—Ç–∞–≤–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Ç–µ–∫—Å—Ç—ã –≤ –≤–∏–¥–µ —á–∏—Å–µ–ª —Å –ø–æ–º–æ—â—å—é
# –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é
# vectorize_sentence –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏
# –û–ø–µ—Ä–∞—Ü–∏—è + –¥–ª—è –¥–≤—É—Ö —Å–ø–∏—Å–∫–æ–≤ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö: [1, 2] + [3, 4] = [1, 2, 3, 4]
vectors = []

for title, text in tqdm(data_tag[['title', 'text']].values):
    vector = vectorize_sentence(title) + vectorize_sentence(text)
    vectors.append(vector)

# üë®üèªüíª –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ 1 —ç–ª–µ–º–µ–Ω—Ç —Å—Ç–∞—Ç—å–∏, —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
#    –∏–ª–∏ —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫
#    (–¥–ª—è —ç—Ç–æ–≥–æ –≤ —Ü–∏–∫–ª–µ –Ω–∞–¥–æ –±—É–¥–µ—Ç –æ—Å—Ç–∞–≤–∏—Ç—å –≤ vector, –Ω–∞–ø—Ä–∏–º–µ—Ä,
#    —Ç–æ–ª—å–∫–æ vectorize_sentence(text))
vectors = np.array(vectors)

#–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è üìù –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –≥—Ä—É–ø–ø—ã. –ï—Å—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, –º—ã –±—É–¥–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π sklearn

from sklearn.cluster import SpectralClustering, KMeans

clusterizer = SpectralClustering(n_clusters=8, n_init=10, random_state=42)

# üë®üèªüíª –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, KMeans.
#    –û–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤: https://scikit-learn.org/stable/modules/clustering.html
# üë®üèªüíª –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å n_clusters=10. –ï—Å—Ç—å –ª–∏ –∫–∞–∫–∏–µ-—Ç–æ –∏–¥–µ–∏, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã–±—Ä–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤?
clusterizer.fit(vectors)

# –î–æ–±–∞–≤–∏–º —Ä–∞–∑–º–µ—Ç–∫—É —Å –Ω–æ–º–µ—Ä–æ–º –∫–ª–∞—Å—Ç–µ—Ä–∞ clusterizer.labels_ –∫–∞–∫ –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É –≤ –¥–∞–Ω–Ω—ã–µ 'label' –≤ —Ç–∞–±–ª–∏—Ü—É data_tag
data_tag['label'] = clusterizer.labels_

data_tag.head(5)

# –ù–∞–±–æ—Ä –º–µ—Ç–æ–∫ data_tag['label'].unique() –æ—Ç—Å–æ—Ä—Ç–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ sorted() –∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç–∫–∏ –≤—ã–≤–µ–¥–µ–º label –∏ –ø–æ–¥—Ç–∞–±–ª–∏—Ü—É —Å—Ç—Ä–æ–∫ —Å —ç—Ç–æ–π
# –º–µ—Ç–∫–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∞ data_tag[data_tag['label'] == label]
for label in sorted(data_tag['label'].unique()):
    print(label)
    display(data_tag[data_tag['label'] == label])
