Построение эффективного вектора признаков — это один из ключевых этапов в анализе данных и машинном обучении. 
Вектор признаков представляет собой числовое представление наблюдаемых объектов, которое позволяет алгоритмам машинного обучения 
обрабатывать данные и делать предсказания. Вектор признаков может включать в себя различные типы данных, такие как числовые значения, категориальные значения, 
текстовые данные и прочее.
а) Числовые признаки являются наиболее распространенными векторами признаков. Они описываются числами и могут иметь как непрерывные, 
так и дискретные значения. В примере с домами это могут быть, например, площадь, количество комнат, стоимость или количество этажей.
б) Категориальные признаки представляют собой описание объекта с помощью категорий или меток. Они могут быть представлены вектором бинарных 
значений или использовать методы кодирования, такие как One-Hot Encoding или Label Encoding. В примере с домами это может быть тип дома (коттедж, апартаменты, таунхаус и т. д.) или наличие бассейна (да/нет).
в) Текстовые признаки могут быть использованы для анализа текстовых данных, таких как отзывы, описания или комментарии. 
Они требуют предварительной обработки с использованием методов NLP (Natural Language Processing), таких как токенизация, 
удаление стоп-слов, лемматизация и т. д
Эти признаки объединяются в один вектор признаков и могут быть использованы далее для обучения модели.
Существует несколько подходов к построению вектора признаков. Наиболее распространенными являются:
1) One-Hot Encoding — это метод, который преобразует категориальные значения признаков в бинарные векторы. Каждое категориальное значение заменяется вектором со значениями 0 и 1, где 1 обозначает принадлежность к соответствующей категории, а 0 — отсутствие принадлежности. 
2) Feature Scaling — это метод, который масштабирует числовые значения признаков для уменьшения влияния различных единиц измерения. Например, если имеются признаки с разными шкалами, такими как рост в сантиметрах и вес в килограммах, то масштабирование позволяет привести их к единому масштабу.
3) Text Tokenization — это метод, который преобразует текстовые данные в последовательности числовых значений (токены). Токены могут быть созданы на основе слов, символов или n-грамм (последовательностей из n элементов). 