#тренировка перцептрона на наблюдениях
import numpy as np
from sklearn.datasets import load_digits

class perceptron():
    digits = load_digits()
    y = digits.target # выбор целевой переменной
    n_samples = len(digits.images) #подготовка данных. Метод reshape преобразует матричную форму
    X = digits.images.reshape((n_samples, -1)) #данных. Например, он может превратить матрицу 10х10 в 100 векторов

    def __init__(self, X, y, threshold = 0.5, learning_rate = 0.1, max_epochs = 10): 
        self.threshold = threshold #переменная threshold определяет точку отсечения между 0 и 1. Она решает какой прогноз будет выдан: 0 или 1. Часто точно отсечение располагается в середине (0.5), но выбор зависит от конкретной ситуации
        self.learning_rate = learning_rate #скоростью обучения алгоритма называется величина поправки, вносимая им при каждом поступлении нового наблюдения. Если поправка высока, то модель быстро адаптируется к новым наблюдениям, но может произойти "перелет", мешающий получению
        #точного результата. Упрощенный пример: оптимальный (и неизвестный) вес переменной х=0.75. Текущая оценка равно 0.4 со скоростью обучения 0.5; поправка = 0.5(скорость обучения) * 1(размер ошибки)* 1(значение х) = 0.5. 0.4(текущий вес) + 0.5(поправка) = 0.9(новый вес) вместо 0.75. Попправка оказалась слишком большой для получения правильного результата.
        self.X = X 
        self.y = y 
        self.max_epochs = max_epochs #под эпохой понимается один прогон по всем данным. Мы разрешаем до 10 прогонов, после которых перцептрон останавливается.

    def initialize(self, init_type = 'zeros'): #функция назначает веса для всех входящих наблюдений. Мы допускаем один из 2-х вариантов: либо веса начинаются с 0, либо им присваиваются небольшие (от 0 до 0.05) случайные значения.
        if init_type == 'random':
            self.weights = np.random.rand(len(self.X[0])) * 0.05 
        if init_type == 'zeros': 
            self.weights = np.zeros(len(self.X[0])) 

    def train(self): #функция тренировки
        epoch = 0 #начинаем с 1-го значения
        while True:
            error_count = 0 #если в конце цикла количество обнаруженных ошибок всё ещё равно нулю, значит алгоритм сошелся и работа закончена
            epoch += 1
            for (X, y) in zip(self.X, self.y):
                error_count += self.train_observation(X, y, error_count)
                if error_count == 0:
                    print ("training successful")
                    break
                if epoch >= self.max_epochs: #если к концу эпохи не обнаружено ошибок, тренировка прошла успешно
                    print ("reached maximum epochs, no perfect prediction")
                    break
                
    def train_observation(self, X, y, error_count): #выполняется для каждого наблюдения и изменяет веса по формуле
        result = np.dot(X, self.weights) > self.threshold #для текущего наблюдения строится прогноз. При бинарном прогнозировании он равен 0 или 1
        error = y - result #реальное значение (у) равно 0 или 1; прогноз тоже равен 0 или 1. Если прогноз ошибочен, мы получаем ошибку 1 или -1
        if error != 0: #если прогноз ошибочен, модель необходимо отрегулировать
            error_count += 1 #число ошибок увеличивается на 1
            for index, value in enumerate(X): #для каждой свободной переменной во входном векторе (Х) регулируется её вес
                self.weights[index] += self.learning_rate * error * value #вес каждой свободной переменной регулируется с использованием значений скорости обучения, ошибки и фактического значения свободной переменной
            return error_count #возвращается счетчик ошибок, потому что его необходимо оценить в конце эпохи
            
        
    def predict(self, X): #класс прогноза
        return int(np.dot(X, self.weights) > self.threshold) #значения свободных переменных умножаются на соответствующие веса (умножение выполняется в np.dot). Результат сравнивается с порогом (в данном случае он равен 0.5) и результат сравнения определяет прогноз: 0 или 1

    X = [(1,0,0),(1,1,0),(1,1,1),(1,1,1),(1,0,1),(1,0,1)] #матрица данных Х (свободные переменные)
    y = [1,1,0,0,1,1] #вектор данных у (целевые данные)

    p = perceptron(X, y) # создаем экземпляр класса perceptron с данными из матрицы Х и вектора у
    p.initialize() #инициализация весов свободных переменных
    p.train() #модель перцептрона прошла тренировку. Она будет пытаться тренироваться до тех пор, пока не сойдется (ошибок больше не будет) или пока не кончатся тренировочные серии (эпохи)
    #проверяем, что теерь спрогнозирует перцептрон с другими значениями свободных переменных
    print (p.predict(1,1,1)) #спрогнозирует 0
    print (p.predict(1,0,1)) #спрогнозирует 1
